<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>实时语音服务构建实践：基于 OpenAI Real-time 协议的技术分享 - lxkaka</title><meta name="Description" content="在人工智能领域，语音交互正变得越来越重要。实时、自然的语音对话体验，是下一代人机交互的关键。本文将深入探讨如何构建一个兼容 OpenAI realtime 协议的端到端的语音模型服务，实现实时的语音识别、自然语言理解和语音合成，最终实现流畅的对话式 AI 体验"><meta property="og:url" content="https://lxkaka.wang/end-to-end-audio-service/">
  <meta property="og:site_name" content="lxkaka">
  <meta property="og:title" content="实时语音服务构建实践：基于 OpenAI Real-time 协议的技术分享">
  <meta property="og:description" content="在人工智能领域，语音交互正变得越来越重要。实时、自然的语音对话体验，是下一代人机交互的关键。本文将深入探讨如何构建一个兼容 OpenAI realtime 协议的端到端的语音模型服务，实现实时的语音识别、自然语言理解和语音合成，最终实现流畅的对话式 AI 体验">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-01-23T15:16:44+08:00">
    <meta property="article:modified_time" content="2025-01-23T15:16:44+08:00">
    <meta property="article:tag" content="Openai Realtime">
    <meta property="article:tag" content="Moshi">
    <meta property="article:tag" content="Audio">
    <meta property="og:image" content="https://lxkaka.wang/logo.png">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://lxkaka.wang/logo.png">
  <meta name="twitter:title" content="实时语音服务构建实践：基于 OpenAI Real-time 协议的技术分享">
  <meta name="twitter:description" content="在人工智能领域，语音交互正变得越来越重要。实时、自然的语音对话体验，是下一代人机交互的关键。本文将深入探讨如何构建一个兼容 OpenAI realtime 协议的端到端的语音模型服务，实现实时的语音识别、自然语言理解和语音合成，最终实现流畅的对话式 AI 体验">
<meta name="application-name" content="lxkaka">
<meta name="apple-mobile-web-app-title" content="lxkaka"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://lxkaka.wang/end-to-end-audio-service/" /><link rel="prev" href="https://lxkaka.wang/llm-parser-agent/" /><link rel="next" href="https://lxkaka.wang/mcp-label-studio/" /><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "实时语音服务构建实践：基于 OpenAI Real-time 协议的技术分享",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/lxkaka.wang\/end-to-end-audio-service\/"
        },"image": {
                "@type": "ImageObject",
                "url": "https:\/\/lxkaka.wang\/cover.png",
                "width":  800 ,
                "height":  600 
            },"genre": "posts","keywords": "openai realtime, moshi, audio","wordcount":  3027 ,
        "url": "https:\/\/lxkaka.wang\/end-to-end-audio-service\/","datePublished": "2025-01-23T15:16:44+08:00","dateModified": "2025-01-23T15:16:44+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
                "@type": "Organization",
                "name": "xxxx",
                "logo": {
                "@type": "ImageObject",
                "url": "https:\/\/lxkaka.wang\/logo.png",
                "width":  127 ,
                "height":  40 
                }
            },"author": {
                "@type": "Person",
                "name": "lxkaka"
            },"description": "在人工智能领域，语音交互正变得越来越重要。实时、自然的语音对话体验，是下一代人机交互的关键。本文将深入探讨如何构建一个兼容 OpenAI realtime 协议的端到端的语音模型服务，实现实时的语音识别、自然语言理解和语音合成，最终实现流畅的对话式 AI 体验"
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="lxkaka"><span class="header-title-pre"><i class='far fa-kiss-wink-heart fa-fw'></i></span>lxkaka</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 所有文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/friend/"> 友链 </a><a class="menu-item" href="/about/"> 关于 </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="lxkaka"><span class="header-title-pre"><i class='far fa-kiss-wink-heart fa-fw'></i></span>lxkaka</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/posts/" title="">所有文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/friend/" title="">友链</a><a class="menu-item" href="/about/" title="">关于</a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">实时语音服务构建实践：基于 OpenAI Real-time 协议的技术分享</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://www.lxkaka.wang" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw"></i>lxkaka</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/ai/"><i class="far fa-folder fa-fw"></i>AI</a>&nbsp;<a href="/categories/%E5%AE%9E%E7%8E%B0/"><i class="far fa-folder fa-fw"></i>实现</a>&nbsp;<a href="/categories/service/"><i class="far fa-folder fa-fw"></i>Service</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2025-01-23">2025-01-23</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 3027 字&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 7 分钟&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#modelmanager模型引擎与资源管理">ModelManager：模型引擎与资源管理</a></li>
        <li><a href="#audioservice协议实现与会话管理中心">AudioService：协议实现与会话管理中心</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>在这里和大家分享一下构建实时语音服务的实践经验，这个服务是基于 OpenAI 最新推出的 Real-time 协议实现的。 随着 AI 技术的快速发展，实时语音交互的应用前景非常广阔，OpenAI Real-time 协议的出现，为开发者构建高性能的实时语音服务提供了有力的工具。在这篇文章中，我介绍一下这个服务的构建过程，包括技术选型、架构设计、核心组件实现以及性能优化策略。希望这些实践经验能对您有所帮助。</p>
<p><strong>系统架构设计</strong></p>
<p>在深入代码之前，先来了解一下系统的整体架构。在设计初期，主要考虑了实时性、可扩展性以及与 OpenAI Real-time 协议的兼容性。 基于这些考虑，最终确定的系统架构如下：</p>
<pre class="mermaid">graph LR
    A["客户端 (Web/App)"] -- "WebSocket" --> B["AudioService"];
    B -- "音频数据 (PCM), 协议事件 (JSON)" --> C["ModelManager"];
    C -- "模型推理" --> B;
    C -- "Mimi 模型 (Encoder/Decoder), LM 模型 (SFT/Base/Pretrain), Tokenizer" --> D["模型权重/配置 (Hugging Face Hub/...)"];
    B -- "ASR 请求 (音频)" --> E["ASR 服务 (OpenAI Whisper/Deepgram/...)"];
    B -- "WebSocket, 事件发送 (send_event)" --> A;
    style D fill:#f9f,stroke:#333,stroke-width:2px;
    style E fill:#ccf,stroke:#333,stroke-width:2px;
    style C fill:#ddf,stroke:#333,stroke-width:2px;
    style B fill:#eee,stroke:#333,stroke-width:2px;
    style A fill:#cef,stroke:#333,stroke-width:2px;
</pre>


<p><strong>架构设计思路:</strong></p>
<ul>
<li><strong>客户端 (Client):</strong>  客户端应用（Web 或 App）负责捕获用户语音，并将音频数据实时推送至音频服务。同时，客户端需要接收并解析服务发出的 OpenAI Real-time 协议事件，最终将语音和文本响应呈现给用户。</li>
<li><strong>音频服务 (AudioService):</strong>  音频服务是系统的核心，主要职责包括：
<ul>
<li><strong>会话管理:</strong>  管理客户端会话的生命周期。</li>
<li><strong>WebSocket 通信:</strong>  建立和维护与客户端的 WebSocket 连接，接收音频数据和协议事件，并推送事件。</li>
<li><strong>音频处理管线:</strong>  构建音频处理流程，包括缓存、分帧、预处理等。</li>
<li><strong>模型推理协调:</strong>  调用模型管理器 (ModelManager) 进行模型推理，并接收推理结果。</li>
<li><strong>ASR 集成 (可选):</strong>  集成 ASR 服务 (OpenAI Whisper, Deepgram, Gemini) 以支持语音转写功能。</li>
<li><strong>OpenAI Real-time 协议实现:</strong>  遵循 OpenAI Real-time 协议，封装事件生成和发送逻辑。</li>
</ul>
</li>
<li><strong>模型管理器 (ModelManager):</strong>  模型管理器负责模型资源的加载、管理和推理，其核心职责包括：
<ul>
<li><strong>模型加载与缓存:</strong>  加载 Mimi 模型、LM 模型、Tokenizer 等模型组件并进行缓存。</li>
<li><strong>模型推理接口:</strong>  提供 <code>process_audio</code> 接口，简化模型推理调用。</li>
<li><strong>模型预热 (Warmup):</strong>  实现模型预热机制，降低首次推理延迟。</li>
<li><strong>并发控制:</strong>  实现并发控制，确保模型在并发访问下的安全性和性能。</li>
</ul>
</li>
<li><strong>ASR 服务 (可选):</strong>  可选集成第三方 ASR 服务，提供语音转写能力。</li>
<li><strong>模型权重/配置:</strong>  模型权重文件和配置信息存储在云端 (Hugging Face Hub) 或本地文件系统。</li>
</ul>
<p><strong>核心组件实现：代码实践</strong></p>
<p>接下来，将分享 <code>ModelManager</code> 和 <code>AudioService</code> 这两个核心组件的代码实现。</p>
<h3 id="modelmanager模型引擎与资源管理">ModelManager：模型引擎与资源管理</h3>
<p><code>ModelManager</code> 类在系统中扮演模型引擎和资源管理的角色。为了高效管理模型资源，采用了<strong>单例模式</strong>来实现 <code>ModelManager</code> 类。</p>
<p><strong>单例模式实现：资源唯一管理</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dataclass</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">ModelManager</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">_instance</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">    <span class="n">_initialized</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># ... 模型组件 ...</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_instance</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">cls</span><span class="o">.</span><span class="n">_instance</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_instance</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@classmethod</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">get_instance</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">hf_repo</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">loaders</span><span class="o">.</span><span class="n">DEFAULT_REPO</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&#34;cuda&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_instance</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_initialized</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">instance</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">hf_repo</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">cls</span><span class="o">.</span><span class="n">_instance</span> <span class="o">=</span> <span class="n">instance</span>
</span></span><span class="line"><span class="cl">            <span class="bp">cls</span><span class="o">.</span><span class="n">_initialized</span> <span class="o">=</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl">            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&#34;Model manager initialized, starting warmup...&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">cls</span><span class="o">.</span><span class="n">_instance</span><span class="o">.</span><span class="n">warmup</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&#34;Model warmup completed&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_instance</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>模型加载与管理：Hugging Face Hub 集成</strong></p>
<p><code>ModelManager</code> 的 <code>from_pretrained</code> 类方法负责加载模型组件。 使用 <code>huggingface_hub</code> 库从 Hugging Face Hub 下载预训练权重。</p>
<p><strong>关键代码 (模型加载)：</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="nd">@classmethod</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">hf_repo</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">loaders</span><span class="o">.</span><span class="n">DEFAULT_REPO</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&#34;cuda&#34;</span><span class="p">,</span> <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&#34;&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ... 初始化锁 ...</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># 加载模型组件</span>
</span></span><span class="line"><span class="cl">        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&#34;loading mimi&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">mimi_weight</span> <span class="o">=</span> <span class="n">hf_hub_download</span><span class="p">(</span><span class="n">hf_repo</span><span class="p">,</span> <span class="n">loaders</span><span class="o">.</span><span class="n">MIMI_NAME</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">mimi</span> <span class="o">=</span> <span class="n">loaders</span><span class="o">.</span><span class="n">get_mimi</span><span class="p">(</span><span class="n">mimi_weight</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&#34;mimi loaded&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Load SFT model</span>
</span></span><span class="line"><span class="cl">        <span class="n">sft_model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&#34;SFT_MODEL&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="n">sft_model_path</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&#34;SFT_MODEL not found&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;loading sft model </span><span class="si">{</span><span class="n">sft_model_path</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">sft_lm</span> <span class="o">=</span> <span class="n">_get_moshi_lm</span><span class="p">(</span><span class="n">sft_model_path</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&#34;sft model loaded&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Load BASE and PRETRAIN models if ENV is set</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ... (加载 BASE 和 PRETRAIN 模型，如果环境变量设置) ...</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">tokenizer_path</span> <span class="o">=</span> <span class="n">hf_hub_download</span><span class="p">(</span><span class="n">hf_repo</span><span class="p">,</span> <span class="n">loaders</span><span class="o">.</span><span class="n">TEXT_TOKENIZER_NAME</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">text_tokenizer</span> <span class="o">=</span> <span class="n">sentencepiece</span><span class="o">.</span><span class="n">SentencePieceProcessor</span><span class="p">(</span><span class="n">tokenizer_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">sft_lm_gen</span> <span class="o">=</span> <span class="n">LMGen</span><span class="p">(</span><span class="n">sft_lm</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># 设置持续推理模式</span>
</span></span><span class="line"><span class="cl">        <span class="n">mimi</span><span class="o">.</span><span class="n">streaming_forever</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">sft_lm_gen</span><span class="o">.</span><span class="n">streaming_forever</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ... (其他初始化) ...</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong><code>process_audio</code> 方法：核心推理流程</strong></p>
<p><code>process_audio</code> 方法是 <code>ModelManager</code> 的核心，负责接收音频 chunk，执行模型推理，并返回文本和音频数据。</p>
<p><strong>关键代码逻辑 (process_audio):</strong></p>
<ol>
<li><strong>音频编码:</strong>  使用 <code>mimi.encode(chunk)</code> 编码音频 chunk。</li>
<li><strong>选择 LM 模型:</strong>  根据 <code>model_type</code> 选择 LM 模型生成器。</li>
<li><strong>循环推理 (Streaming):</strong>  循环遍历 codes，调用 LM 模型的 <code>step</code> 方法进行流式推理。</li>
<li><strong>音频解码 (如果生成 tokens):</strong>  使用 <code>mimi.decode(tokens[:, 1:])</code> 解码 tokens 为音频 PCM 数据。</li>
<li><strong>文本 token 转换 (如果生成 tokens):</strong>  使用 <code>text_tokenizer.id_to_piece</code> 将 token ID 转换为文本片段。</li>
<li><strong>返回结果:</strong>  返回文本消息和音频 PCM 数据。</li>
</ol>
<p><strong>代码片段 (process_audio 核心逻辑):</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="nd">@torch.inference_mode</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">process_audio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chunk</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">model_type</span> <span class="p">:</span><span class="nb">str</span> <span class="o">=</span> <span class="s2">&#34;sft&#34;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;处理音频并生成响应&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">codes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">text_msg</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="n">audio_pcm</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">codes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">            <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lm_gen</span><span class="p">(</span><span class="n">model_type</span><span class="p">)</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">codes</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">c</span> <span class="p">:</span> <span class="n">c</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span> <span class="c1"># 模型推理</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">tokens</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">continue</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">pcm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mimi</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tokens</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span> <span class="c1"># 音频解码</span>
</span></span><span class="line"><span class="cl">            <span class="n">audio_pcm</span> <span class="o">=</span> <span class="n">pcm</span><span class="o">.</span><span class="n">cpu</span><span class="p">()[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">text_token</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">text_token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_tokenizer</span><span class="o">.</span><span class="n">id_to_piece</span><span class="p">(</span><span class="n">text_token</span><span class="p">)</span> <span class="c1"># token -&gt; 文本</span>
</span></span><span class="line"><span class="cl">                <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34; &#34;</span><span class="p">,</span> <span class="s2">&#34; &#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">text_msg</span> <span class="o">=</span> <span class="n">text</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">text_msg</span><span class="p">,</span> <span class="n">audio_pcm</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>并发控制与模型预热：性能提升</strong></p>
<ul>
<li><strong><code>asyncio.Lock</code></strong>:  使用 <code>asyncio.Lock</code> 保证并发场景下模型访问安全。</li>
<li><strong><code>warmup</code> 方法</strong>:  <code>warmup</code> 方法在初始化后调用，预热模型，降低推理延迟。</li>
</ul>
<h3 id="audioservice协议实现与会话管理中心">AudioService：协议实现与会话管理中心</h3>
<p><code>AudioService</code> 负责处理客户端 WebSocket 连接、会话管理、音频处理流程以及 OpenAI Real-time 协议交互。</p>
<p><strong>会话管理与状态维护：<code>SessionState</code> 数据类</strong></p>
<p>使用 <code>self.sessions</code> 字典管理会话状态 (<code>SessionState</code>)。 <code>create_session</code> 方法创建新会话并初始化 <code>SessionState</code> 对象。</p>
<p><strong><code>SessionState</code> 数据类定义：</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dataclass</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">SessionState</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">session</span><span class="p">:</span> <span class="n">Resource</span><span class="o">.</span><span class="n">Session</span>
</span></span><span class="line"><span class="cl">    <span class="n">conversation</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Resource</span><span class="o">.</span><span class="n">Conversation</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">    <span class="n">current_response</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Resource</span><span class="o">.</span><span class="n">Response</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">    <span class="n">audio_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">AudioState</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">first_sent</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># 是否已经发送过第一个音频响应</span>
</span></span><span class="line"><span class="cl">    <span class="n">item_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># 当前音频响应的item_id</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># ... 索引计数器 ...</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">reset_audio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ... 重置音频状态和索引 ...</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>WebSocket 事件处理 (<code>handle_client</code> 方法)：事件驱动架构</strong></p>
<p><code>handle_client</code> 方法处理客户端 WebSocket 连接，监听并处理不同类型的事件。</p>
<p><strong>关键代码逻辑 (handle_client):</strong></p>
<ol>
<li><strong>创建会话:</strong>  调用 <code>self.create_session()</code> 创建会话状态。</li>
<li><strong>发送初始化事件:</strong>  发送 <code>session.created</code> 和 <code>conversation.created</code> 事件。</li>
<li><strong>启动音频流处理任务 (<code>handle_audio_stream</code>):</strong>  创建异步任务处理音频流。</li>
<li><strong>事件接收循环:</strong>  循环监听客户端 WebSocket 消息。</li>
<li><strong>事件解析:</strong>  解析 JSON 消息，获取事件类型和数据。</li>
<li><strong>事件分发处理:</strong>  根据 <code>event[&quot;type&quot;]</code> 执行不同逻辑 (session.update, input_audio_buffer.append, response.cancel 等)。</li>
<li><strong>错误处理和资源清理:</strong>  使用 <code>try...except...finally</code> 结构进行错误处理和资源清理。</li>
</ol>
<p><strong>音频流处理 (<code>handle_audio_stream</code> 方法)：实时响应引擎</strong></p>
<p><code>handle_audio_stream</code> 方法负责音频数据读取、分帧、模型推理以及实时响应发送。 包含 <code>audio_process_loop</code> 和 <code>transcription_loop</code> 两个异步循环。</p>
<p><strong>关键代码逻辑 (<code>audio_process_loop</code>):</strong></p>
<ol>
<li><strong>循环读取 PCM 数据:</strong>  从 <code>audio_state.pcm_buffer.read_pcm()</code> 读取 PCM 数据。</li>
<li><strong>音频数据累积与分帧:</strong>  累积 PCM 数据到 <code>audio_state.all_pcm_data</code>，并分帧处理。</li>
<li><strong>模型推理:</strong>  将音频 chunk 转换为 Tensor，调用 <code>self.process_audio_and_generate</code> 进行推理。</li>
<li><strong>音频/文本响应实时发送:</strong>  使用 <code>send_event</code> 发送 <code>response.audio.delta</code> 和 <code>response.audio_transcript.delta</code> 事件。</li>
<li><strong>Real-time 协议事件封装:</strong>  在首次发送音频响应前，发送 <code>response.output_item.added</code> 和 <code>response.content_part.added</code> 事件。</li>
</ol>
<p><strong>关键代码逻辑 (<code>transcription_loop</code>):</strong></p>
<p><code>transcription_loop</code> 异步处理音频转写任务，定期检查 <code>audio_state.transcription_buffer</code> 中的音频数据，发送给 ASR 服务转写，并通过 <code>conversation.item.input_audio_transcription.completed</code> 事件发送结果。</p>
<p><strong>Client-Server Event 时序图：协议交互流程</strong></p>
<pre class="mermaid">sequenceDiagram
    participant Client
    participant Server

    Note over Client,Server: 会话初始化
    Client->>Server: WebSocket 连接建立
    Server->>Client: event: session.created
    Server->>Client: event: conversation.created

    Note over Client,Server: 音频输入开始
    Client->>Server: event: input_audio_buffer.append (音频 Chunk 1)
    Server->>Server: 音频处理 (ModelManager)
    Server->>Client: event: response.created
    Server->>Client: event: response.output_item.added (音频输出项)
    Server->>Client: event: response.content_part.added (音频内容部分)
    Server->>Client: event: response.audio.delta (音频 Delta 1)
    Server->>Client: event: response.audio_transcript.delta (文本 Delta 1, 可选)

    Client->>Server: event: input_audio_buffer.append (音频 Chunk 2)
    Server->>Server: 音频处理 (ModelManager)
    Server->>Client: event: response.audio.delta (音频 Delta 2)
    Server->>Client: event: response.audio_transcript.delta (文本 Delta 2, 可选)
    Note over Client,Server: (持续音频 Chunk 和 Delta 事件)

    Note over Client,Server: 音频转写完成 (异步)
    Server->>Client: event: conversation.item.input_audio_transcription.completed (转写文本)

    Note over Client,Server: 会话更新 (可选)
    Client->>Server: event: session.update (更新 Session 参数)
    Server->>Client: event: session.updated

    Note over Client,Server: 客户端取消响应 (可选)
    Client->>Server: event: response.cancel
    Server->>Client: event: response.done (status: cancelled)

    Note over Client,Server: 会话结束 (隐式 - 连接断开或超时)
    Client->>Server: WebSocket 连接关闭
    Server->>Server: 清理会话资源

    Note over Server,Client: 错误处理 (Server 侧发生错误)
    Server->>Client: event: error (error details)
</pre>


<p><strong>性能优化：实践经验</strong></p>
<p>性能优化策略包括：</p>
<ul>
<li><strong>GPU 加速：</strong>  模型推理 GPU 加速。</li>
<li><strong>异步编程 (asyncio)：</strong>  <code>AudioService</code> 基于 <code>asyncio</code> 构建，实现高并发和低延迟。</li>
<li><strong>流式推理 (Streaming Inference)：</strong>  利用 Mimi 模型和 LM 模型的流式推理特性。</li>
<li><strong>音频分帧处理：</strong>  音频流分割成固定大小的帧 (chunk, <code>frame_size</code>) 处理。</li>
<li><strong>模型预热 (Warmup)：</strong>  服务启动时进行模型预热。</li>
<li><strong>模型单例模式：</strong>  <code>ModelManager</code> 单例模式避免重复加载模型。</li>
<li><strong>高效数据结构：</strong>  使用 <code>PCM16Buffer</code> 和 <code>TranscriptionBuffer</code> 等高效数据结构。</li>
</ul>
<p><strong>未来展望：服务进化</strong></p>
<p>未来的改进方向包括：</p>
<ul>
<li><strong>更强大的 ASR 服务集成：</strong>  提升语音转写准确率和鲁棒性。</li>
<li><strong>多轮对话能力：</strong>  支持对话上下文管理，实现多轮对话。</li>
<li><strong>模型多样性与灵活配置：</strong>  支持更多模型选择和配置选项。</li>
<li><strong>Tool/Function Calling 功能：</strong>  集成 Tool/Function Calling 功能。</li>
<li><strong>服务部署与弹性伸缩：</strong>  研究服务部署方案和弹性伸缩能力。</li>
<li><strong>安全性加固：</strong>  加强服务安全性设计。</li>
</ul>
<p><strong>总结：构建心得</strong></p>
<p>构建基于 OpenAI Real-time 协议的实时语音服务是一次有益的实践。 通过这篇文章，希望能够分享一些实践经验，帮助开发者了解 OpenAI Real-time 协议，并构建出更优秀的实时语音交互应用。 感谢阅读！</p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2025-01-23</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/end-to-end-audio-service/index.md" target="_blank">阅读原始文档</a>
                        </span></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="https://lxkaka.wang/end-to-end-audio-service/" data-title="实时语音服务构建实践：基于 OpenAI Real-time 协议的技术分享" data-hashtags="openai realtime,moshi,audio"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="https://lxkaka.wang/end-to-end-audio-service/" data-hashtag="openai realtime"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="分享到 WhatsApp" data-sharer="whatsapp" data-url="https://lxkaka.wang/end-to-end-audio-service/" data-title="实时语音服务构建实践：基于 OpenAI Real-time 协议的技术分享" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="https://lxkaka.wang/end-to-end-audio-service/" data-title="实时语音服务构建实践：基于 OpenAI Real-time 协议的技术分享"><i class="fab fa-weibo fa-fw"></i></a><a href="javascript:void(0);" title="分享到 百度" data-sharer="baidu" data-url="https://lxkaka.wang/end-to-end-audio-service/" data-title="实时语音服务构建实践：基于 OpenAI Real-time 协议的技术分享"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@2.12.0/icons/baidu.svg"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/openai-realtime/">Openai Realtime</a>,&nbsp;<a href="/tags/moshi/">Moshi</a>,&nbsp;<a href="/tags/audio/">Audio</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/llm-parser-agent/" class="prev" rel="prev" title="告别手动写代码：我的商品数据解析器 Agent 设计思路与方案"><i class="fas fa-angle-left fa-fw"></i>告别手动写代码：我的商品数据解析器 Agent 设计思路与方案</a>
            <a href="/mcp-label-studio/" class="next" rel="next" title="对话式指令革新标注管理：从手动Label Studio操作到MCP Server驱动的自动化工作流">对话式指令革新标注管理：从手动Label Studio操作到MCP Server驱动的自动化工作流<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"><div id="disqus_thread" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://disqus.com/?ref_noscript">Disqus</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Welcome to lxkaka's blog</div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2017 - 2025</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://www.lxkaka.wang" target="_blank">lxkaka</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><script type="text/javascript" src="https://lxkaka.disqus.com/embed.js" defer></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.37.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lunr@2.3.8/lunr.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.stemmer.support.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.zh.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.2.0/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.4.0/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":10},"comment":{},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","lunrLanguageCode":"zh","lunrSegmentitURL":"/lib/lunr/lunr.segmentit.js","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'UA-173214698-1', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=UA-173214698-1" async></script></body>
</html>


  <script type="module">
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
    mermaid.initialize({ startOnLoad: true });
  </script>


