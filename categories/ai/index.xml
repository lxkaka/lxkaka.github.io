<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>AI - 分类 - lxkaka</title>
        <link>https://lxkaka.wang/categories/ai/</link>
        <description>AI - 分类 - lxkaka</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>linxiaoking@gmail.com (lxkaka)</managingEditor>
            <webMaster>linxiaoking@gmail.com (lxkaka)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Tue, 24 Oct 2023 13:34:55 &#43;0800</lastBuildDate><atom:link href="https://lxkaka.wang/categories/ai/" rel="self" type="application/rss+xml" /><item>
    <title>Transformer 结构学习总结</title>
    <link>https://lxkaka.wang/learn-transformer/</link>
    <pubDate>Tue, 24 Oct 2023 13:34:55 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://lxkaka.wang/learn-transformer/</guid>
    <description><![CDATA[MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']], processEscapes: true}, jax: ["input/TeX","input/MathML","input/AsciiMath","output/CommonHTML"], extensions: ["tex2jax.js","mml2jax.js","asciimath2jax.js","MathMenu.js","MathZoom.js","AssistiveMML.js", "[Contrib]/a11y/accessibility-menu.js"], TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"], equationNumbers: { autoNumber: "AMS" } } }); transformer 已经成了当前深度学习领域最著名的网络架构，它是各大语言模型的基石。在这篇文章里我把自己在了]]></description>
</item><item>
    <title>AI 助力 Code Review 的高效方案</title>
    <link>https://lxkaka.wang/llm-code-review/</link>
    <pubDate>Sun, 20 Aug 2023 11:22:28 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://lxkaka.wang/llm-code-review/</guid>
    <description><![CDATA[背景 随着 LLM 的日益强大，我们可以借助 LLM 来提高多方面的生产效率。很多的应用场景我们就不在这里展开，其中一方面就是用来给程序员提效，比如大名鼎鼎的]]></description>
</item></channel>
</rss>
